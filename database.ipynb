{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "from collections import Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('metadata.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS conversation_logs (\n",
    "        timestamp TEXT PRIMARY KEY,\n",
    "        conversation_id TEXT,\n",
    "        prompt TEXT,\n",
    "        response TEXT,\n",
    "        original_book_id Text,\n",
    "        predicted_book_id Text,\n",
    "        response_type Text,\n",
    "        solar_documents_return_count INT\n",
    "    )\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('metadata.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS conversation_logs (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        timestamp TEXT,\n",
    "        conversation_id TEXT,\n",
    "        prompt TEXT,\n",
    "        response TEXT,\n",
    "        original_book_id Text,\n",
    "        predicted_book_id Text,\n",
    "        response_type Text,\n",
    "        solar_documents_return_count INT\n",
    "    )\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('metadata.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('DROP TABLE IF EXISTS conversation_logs')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('metadata.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('SELECT * FROM conversation_logs')\n",
    "\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_conversation(timestamp, conversation_id, prompt, response, original_book_id, predicted_book_id, response_type, solar_documents_return_count):\n",
    "    conn = sqlite3.connect('metadata.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        INSERT INTO conversation_logs (timestamp, conversation_id, prompt, response, original_book_id, predicted_book_id, response_type, solar_documents_return_count) \n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', [timestamp, conversation_id, prompt, response, original_book_id, predicted_book_id, response_type, solar_documents_return_count])\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "sessions = 10\n",
    "\n",
    "sleep_time = range(0,10)\n",
    "\n",
    "# Prompts\n",
    "prompts = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How to bake a chocolate cake?\",\n",
    "    \"Explain the theory of relativity\"\n",
    "]\n",
    "\n",
    "# Responses\n",
    "responses = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"To bake a chocolate cake, you need to mix flour, sugar, cocoa powder, and other ingredients, then bake it in an oven.\",\n",
    "    \"The theory of relativity, proposed by Albert Einstein, describes the laws of physics in the context of moving frames of reference.\"\n",
    "]\n",
    "\n",
    "# Original Book IDs (with one value as None)\n",
    "original_book_ids = [12345, None, 67890]  # Using None for NULL\n",
    "\n",
    "# Predicted Book IDs\n",
    "predicted_book_ids = [54321, 98765, 12321]\n",
    "\n",
    "# Response Types\n",
    "response_types = [\"Information\", \"Instruction\", \"Explanation\"]\n",
    "\n",
    "# Solar Documents Return Count\n",
    "solar_documents_return_counts = [5, 10, 3]\n",
    "\n",
    "\n",
    "for sess_id in range(1,sessions+1):\n",
    "    number_of_conversations = random.choice(range(0, 9))\n",
    "    \n",
    "    for conv_id in range(1, number_of_conversations+1):\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "        conversation_id = sess_id\n",
    "        prompt = random.choice(prompts)\n",
    "        response = random.choice(responses)\n",
    "        original_book_id = random.choice(original_book_ids)\n",
    "        predicted_book_id = random.choice(predicted_book_ids)\n",
    "        response_type = random.choice(response_types)\n",
    "        solar_documents_return_count = random.choice(solar_documents_return_counts)\n",
    "        insert_conversation(timestamp, conversation_id, prompt, response, original_book_id, predicted_book_id, response_type, solar_documents_return_count)\n",
    "        time.sleep(random.choice(sleep_time))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('metadata.sqlite')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"SELECT *\n",
    "                FROM conversation_logs\n",
    "               \"\"\")\n",
    "rows = cursor.fetchall()\n",
    "print(rows)\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generator():\n",
    "    \n",
    "    plot_data = {}\n",
    "    \n",
    "    \n",
    "    # Generate Timeseries Plot\n",
    "    conn = sqlite3.connect('metadata.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT timestamp FROM conversation_logs')\n",
    "    timestamps = [datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S.%f') for row in cursor.fetchall()]\n",
    "    conversations_per_hour = Counter([timestamp.replace(minute=0, second=0, microsecond=0) for timestamp in timestamps])\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    times = list(conversations_per_hour.keys())\n",
    "    counts = list(conversations_per_hour.values())\n",
    "    \n",
    "    # Plotly data\n",
    "    conversations_over_time = {\n",
    "        'data': [{'x': times, 'y': counts, 'type': 'timeseries'}],\n",
    "        'layout': {'title': 'Conversations Over Time'}\n",
    "    }\n",
    "    plot_data['conversations_over_time'] = conversations_over_time\n",
    "    \n",
    "    \n",
    "    # Average Number of Conversations Per Session\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "               SELECT AVG(conversation_count) AS average_conversations_per_id\n",
    "                FROM (\n",
    "                SELECT conversation_id, COUNT(*) AS conversation_count\n",
    "                FROM conversation_logs\n",
    "                GROUP BY conversation_id\n",
    "                ) AS subquery;\n",
    "            \"\"\")\n",
    "    plot_data['average_number_of_conversations_in_a_session'] = cursor.fetchall()[0][0]\n",
    "    \n",
    "    \n",
    "    # Book Distribution\n",
    "    \n",
    "    cursor.execute('''\n",
    "    SELECT original_book_id, COUNT(*) as count\n",
    "    FROM conversation_logs\n",
    "    WHERE original_book_id IS NOT NULL\n",
    "    GROUP BY original_book_id\n",
    "    ORDER BY count DESC;\n",
    "    ''')\n",
    "    \n",
    "    book_ids = []\n",
    "    counts = []\n",
    "    \n",
    "    for row in cursor.fetchall():\n",
    "        book_ids.append(row[0])\n",
    "        counts.append(row[1])\n",
    "    \n",
    "    \n",
    "    book_distribution = {\n",
    "        'data': [{'x': book_ids, 'y': counts, 'type': 'bar'}],\n",
    "        'layout': {'title': 'Book Distribution'}\n",
    "    }\n",
    "    \n",
    "    plot_data['book_distribution'] = book_distribution\n",
    "    \n",
    "    \n",
    "    # Calcualte Accuracy\n",
    "    cursor.execute(\"\"\"\n",
    "                SELECT COUNT(*) FROM conversation_logs\n",
    "                WHERE original_book_id IS NOT NULL AND predicted_book_id IS NOT NULL AND original_book_id = predicted_book_id;\n",
    "                \"\"\")\n",
    "    \n",
    "    matched = cursor.fetchall()[0][0]\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "                SELECT COUNT(*) FROM conversation_logs\n",
    "                WHERE original_book_id IS NOT NULL AND predicted_book_id IS NOT NULL;\n",
    "                \"\"\")\n",
    "    total = cursor.fetchall()[0][0]\n",
    "    book_classifier_accuracy = 0\n",
    "    if total != 0:\n",
    "        book_classifier_accuracy = matched/total\n",
    "        \n",
    "    \n",
    "    plot_data['book_classifier_accuracy'] = book_classifier_accuracy\n",
    "    \n",
    "    \n",
    "    # Response Type Distribution\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "               SELECT response_type, COUNT(*) as count\n",
    "                FROM conversation_logs\n",
    "                GROUP BY response_type\n",
    "                ORDER BY count DESC;\n",
    "               \"\"\")\n",
    "    \n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    response_types = []\n",
    "    counts = []\n",
    "    \n",
    "    for row in rows:\n",
    "        response_types.append(row[0])\n",
    "        counts.append(row[1])\n",
    "    \n",
    "    \n",
    "    response_distribution = {\n",
    "        'data': [{'x': response_types, 'y': counts, 'type': 'bar'}],\n",
    "        'layout': {'title': 'Response Distribution'}\n",
    "    }\n",
    "    \n",
    "    plot_data['response_distribution'] = response_distribution\n",
    "    \n",
    "    # Solar Document Book Distribution Type Distribution\n",
    "    cursor.execute(\"\"\"\n",
    "               SELECT original_book_id, SUM(solar_documents_return_count) as Frequency\n",
    "                FROM conversation_logs\n",
    "                WHERE original_book_id IS NOT NULL\n",
    "                GROUP BY original_book_id;\n",
    "               \"\"\")\n",
    "    book_ids = []\n",
    "    counts = []\n",
    "    \n",
    "    for row in cursor.fetchall():\n",
    "        book_ids.append(row[0])\n",
    "        counts.append(row[1])\n",
    "    \n",
    "    \n",
    "    solr_documents_distribution_across_books = {\n",
    "        'data': [{'x': book_ids, 'y': counts, 'type': 'bar'}],\n",
    "        'layout': {'title': 'Solr distribution across Books'}\n",
    "    }\n",
    "    \n",
    "    plot_data['solr_documents_distribution_across_booksdistribution'] = solr_documents_distribution_across_books\n",
    "    \n",
    "    \n",
    "    # Average Number of Documents Retrieved Per Session\n",
    "    cursor.execute(\"\"\"\n",
    "               SELECT AVG(SumOfDocuments) as AvgDocumentsPerConversation\n",
    "                FROM (\n",
    "                    SELECT conversation_id, SUM(solar_documents_return_count) as SumOfDocuments\n",
    "                    FROM conversation_logs\n",
    "                    GROUP BY conversation_id\n",
    "                ) as SubQuery;\n",
    "               \"\"\")\n",
    "    \n",
    "    plot_data['average_number_of_solr_documents_fetched_in_a_session'] = cursor.fetchall()[0][0]\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "               SELECT COUNT(DISTINCT conversation_id) as TotalUniqueConversations\n",
    "                FROM conversation_logs;\n",
    "               \"\"\")\n",
    "    plot_data['total_number_of_sessions'] = cursor.fetchall()[0][0]\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = plot_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plots.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations_over_time': {'data': [{'x': [datetime.datetime(2023, 12, 10, 0, 0)],\n",
       "    'y': [45],\n",
       "    'type': 'timeseries'}],\n",
       "  'layout': {'title': 'Conversations Over Time'}},\n",
       " 'average_number_of_conversations_in_a_session': 5.0,\n",
       " 'book_distribution': {'data': [{'x': ['12345', '67890'],\n",
       "    'y': [18, 10],\n",
       "    'type': 'bar'}],\n",
       "  'layout': {'title': 'Book Distribution'}},\n",
       " 'book_classifier_accuracy': 0.0,\n",
       " 'response_distribution': {'data': [{'x': ['Information',\n",
       "     'Explanation',\n",
       "     'Instruction'],\n",
       "    'y': [18, 16, 11],\n",
       "    'type': 'bar'}],\n",
       "  'layout': {'title': 'Response Distribution'}},\n",
       " 'solr_documents_distribution_across_booksistribution': {'data': [{'x': [3,\n",
       "     5,\n",
       "     10],\n",
       "    'y': [17, 12, 16],\n",
       "    'type': 'bar'}],\n",
       "  'layout': {'title': 'Solr distribution across Books'}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/insert_conversation', methods=['POST'])\n",
    "def insert_conversation_endpoint():\n",
    "    data = request.json\n",
    "    conn = sqlite3.connect('metadata.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        INSERT INTO conversation_logs (timestamp, conversation_id, prompt, response, original_book_id, predicted_book_id, response_type, solar_documents_return_count) \n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', [data['timestamp'], data['conversation_id'], data['prompt'], data['response'], data['original_book_id'], data['predicted_book_id'], data['response_type'], data['solar_documents_return_count']])\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return jsonify({\"status\": \"success\"})\n",
    "\n",
    "@app.route('/plot_generator', methods=['GET'])\n",
    "def plot_generator():\n",
    "    plot_data = {}\n",
    "\n",
    "    conn = sqlite3.connect('metadata.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Generate Timeseries Plot\n",
    "    cursor.execute('SELECT timestamp FROM conversation_logs')\n",
    "    timestamps = [datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S.%f') for row in cursor.fetchall()]\n",
    "    conversations_per_minute = Counter([timestamp.replace(second=0, microsecond=0) for timestamp in timestamps])\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    times = list(conversations_per_minute.keys())\n",
    "    counts = list(conversations_per_minute.values())\n",
    "\n",
    "    # Plotly data\n",
    "    conversations_over_time = {\n",
    "        'data': [{'x': times, 'y': counts, 'type': 'timeseries'}],\n",
    "        'layout': {'title': 'Conversations Over Time'}\n",
    "    }\n",
    "    plot_data['conversations_over_time'] = conversations_over_time\n",
    "\n",
    "    # Average Number of Conversations Per Session\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT AVG(conversation_count) AS average_conversations_per_id\n",
    "        FROM (\n",
    "            SELECT conversation_id, COUNT(*) AS conversation_count\n",
    "            FROM conversation_logs\n",
    "            GROUP BY conversation_id\n",
    "        ) AS subquery;\n",
    "    \"\"\")\n",
    "    plot_data['average_number_of_conversations_in_a_session'] = cursor.fetchall()[0][0]\n",
    "\n",
    "    # Book Distribution\n",
    "    cursor.execute('''\n",
    "        SELECT original_book_id, COUNT(*) as count\n",
    "        FROM conversation_logs\n",
    "        WHERE original_book_id IS NOT NULL\n",
    "        GROUP BY original_book_id\n",
    "        ORDER BY count DESC;\n",
    "    ''')\n",
    "    book_ids = []\n",
    "    counts = []\n",
    "    for row in cursor.fetchall():\n",
    "        book_ids.append(row[0])\n",
    "        counts.append(row[1])\n",
    "\n",
    "    book_distribution = {\n",
    "        'data': [{'x': book_ids, 'y': counts, 'type': 'bar'}],\n",
    "        'layout': {'title': 'Book Distribution'}\n",
    "    }\n",
    "    plot_data['book_distribution'] = book_distribution\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM conversation_logs\n",
    "        WHERE original_book_id IS NOT NULL AND original_book_id = predicted_book_id;\n",
    "    \"\"\")\n",
    "    matched = cursor.fetchall()[0][0]\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM conversation_logs\n",
    "        WHERE original_book_id IS NOT NULL;\n",
    "    \"\"\")\n",
    "    total = cursor.fetchall()[0][0]\n",
    "\n",
    "    book_classifier_accuracy = matched / total\n",
    "    plot_data['book_classifier_accuracy'] = book_classifier_accuracy\n",
    "\n",
    "    # Response Type Distribution\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT response_type, COUNT(*) as count\n",
    "        FROM conversation_logs\n",
    "        GROUP BY response_type\n",
    "        ORDER BY count DESC;\n",
    "    \"\"\")\n",
    "    rows = cursor.fetchall()\n",
    "    response_types = []\n",
    "    counts = []\n",
    "    for row in rows:\n",
    "        response_types.append(row[0])\n",
    "        counts.append(row[1])\n",
    "\n",
    "    response_distribution = {\n",
    "        'data': [{'x': response_types, 'y': counts, 'type': 'bar'}],\n",
    "        'layout': {'title': 'Response Distribution'}\n",
    "    }\n",
    "    plot_data['response_distribution'] = response_distribution\n",
    "\n",
    "    conn.close()\n",
    "    return jsonify(plot_data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data copied successfully from 'conversation_logs' to 'conversation_logs2'.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('metadata.sqlite')\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''ALTER TABLE conversation_logs RENAME TO temp_table;''')\n",
    "\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS conversation_logs (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        timestamp TEXT,\n",
    "        conversation_id TEXT,\n",
    "        prompt TEXT,\n",
    "        response TEXT,\n",
    "        original_book_id Text,\n",
    "        predicted_book_id Text,\n",
    "        response_type Text,\n",
    "        solar_documents_return_count INT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Copy data from conversation_logs to conversation_logs2\n",
    "cursor.execute('''\n",
    "    INSERT INTO conversation_logs (timestamp, conversation_id, prompt, response, original_book_id, predicted_book_id, response_type, solar_documents_return_count)\n",
    "    SELECT timestamp, conversation_id, prompt, response, original_book_id, predicted_book_id, response_type, solar_documents_return_count\n",
    "    FROM temp_table\n",
    "''')\n",
    "\n",
    "\n",
    "cursor.execute('DROP TABLE IF EXISTS temp_table')\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "\"Data copied successfully from 'conversation_logs' to 'conversation_logs2'.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
